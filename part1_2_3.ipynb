{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.estimators import HillClimbSearch, K2Score, MaximumLikelihoodEstimator, ParameterEstimator, BayesianEstimator\n",
    "from pgmpy.sampling import BayesianModelSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except (ValueError, TypeError):\n",
    "        return s\n",
    "\n",
    "def percentage(s):\n",
    "    try:\n",
    "        return s / 100.\n",
    "    except (ValueError, TypeError):\n",
    "        return s\n",
    "\n",
    "def remove_none(s):\n",
    "    if s is '':\n",
    "        return 0\n",
    "    return str(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78  0.275 0.18  0.715 0.375 0.015]\n",
      " [0.015 0.32  0.66  0.105 0.11  0.32 ]\n",
      " [0.055 0.025 0.16  0.01  0.105 0.14 ]\n",
      " [0.15  0.17  0.    0.17  0.41  0.315]\n",
      " [0.    0.21  0.    0.    0.    0.21 ]]\n"
     ]
    }
   ],
   "source": [
    "marginalProb_file = ('data/Table2.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(marginalProb_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "        \n",
    "marginalProb = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        marginalProb.append(a[0])\n",
    "    \n",
    "marginalProb = np.reshape(marginalProb, (np.shape(rawData)[0], -1))\n",
    "marginalProb_clean = marginalProb[1:, 1:]\n",
    "margProb = marginalProb_clean.astype(np.float)\n",
    "print(margProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78  0.015 0.055 0.15 ]\n",
      " [0.231 0.666 0.455 0.4  ]\n",
      " [0.365 0.    0.091 0.2  ]\n",
      " [0.026 0.    0.    0.033]\n",
      " [0.173 0.    0.182 0.167]\n",
      " [0.205 0.333 0.273 0.2  ]\n",
      " [0.737 1.    0.727 0.567]\n",
      " [0.077 0.    0.273 0.2  ]\n",
      " [0.013 0.    0.    0.   ]\n",
      " [0.173 0.    0.    0.233]\n",
      " [0.019 0.    0.    0.   ]\n",
      " [0.282 0.666 0.545 0.4  ]\n",
      " [0.128 0.333 0.091 0.2  ]\n",
      " [0.352 0.    0.182 0.2  ]\n",
      " [0.218 0.    0.182 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "table3_file = ('data/Table3.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table3_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "        \n",
    "table3 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table3.append(a[0])\n",
    "    \n",
    "table3 = np.reshape(table3, (np.shape(rawData)[0], -1))\n",
    "table3_clean = table3[1:, 1:]\n",
    "cpd_x1 = table3_clean.astype(np.float)\n",
    "print(cpd_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.275 0.32  0.025 0.17  0.21 ]\n",
      " [0.127 0.266 0.2   0.176 0.119]\n",
      " [0.745 0.656 0.8   0.706 0.5  ]\n",
      " [0.127 0.078 0.    0.118 0.381]\n",
      " [0.418 0.344 0.6   0.382 0.334]\n",
      " [0.073 0.109 0.4   0.147 0.095]\n",
      " [0.109 0.125 0.    0.118 0.071]\n",
      " [0.4   0.422 0.    0.353 0.5  ]]\n"
     ]
    }
   ],
   "source": [
    "table4_file = ('data/Table4.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table4_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "\n",
    "table4 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table4.append(a[0])\n",
    "    \n",
    "table4 = np.reshape(table4, (np.shape(rawData)[0], -1))\n",
    "table4_clean = table4[1:, 1:]\n",
    "cpd_x2 = table4_clean.astype(np.float)\n",
    "cpd_x2[4,1] = 0.344\n",
    "print(cpd_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18   0.66   0.16  ]\n",
      " [0.194  0.311  0.219 ]\n",
      " [0.472  0.318  0.156 ]\n",
      " [0.028  0.0303 0.    ]\n",
      " [0.167  0.182  0.125 ]\n",
      " [0.139  0.159  0.5   ]\n",
      " [0.361  0.394  0.313 ]\n",
      " [0.083  0.114  0.125 ]\n",
      " [0.222  0.091  0.031 ]\n",
      " [0.333  0.402  0.531 ]\n",
      " [0.     0.023  0.    ]\n",
      " [0.389  0.318  0.25  ]\n",
      " [0.083  0.152  0.156 ]\n",
      " [0.361  0.303  0.203 ]\n",
      " [0.167  0.204  0.281 ]]\n"
     ]
    }
   ],
   "source": [
    "table5_file = ('data/Table5.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table5_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "\n",
    "table5 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table5.append(a[0])\n",
    "    \n",
    "table5 = np.reshape(table5, (np.shape(rawData)[0], -1))\n",
    "table5_clean = table5[1:, 1:]\n",
    "cpd_x3 = table5_clean.astype(np.float)\n",
    "print(cpd_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.715 0.105 0.01  0.17 ]\n",
      " [0.804 0.571 1.    0.794]\n",
      " [0.021 0.    0.    0.   ]\n",
      " [0.056 0.143 0.    0.   ]\n",
      " [0.119 0.286 0.    0.206]\n",
      " [0.308 0.238 0.    0.176]\n",
      " [0.322 0.286 1.    0.323]\n",
      " [0.028 0.    0.    0.029]\n",
      " [0.154 0.19  0.    0.235]\n",
      " [0.196 0.286 0.    0.235]\n",
      " [0.021 0.    0.    0.   ]\n",
      " [0.28  0.571 0.    0.353]\n",
      " [0.154 0.143 0.    0.088]\n",
      " [0.329 0.19  0.5   0.323]\n",
      " [0.217 0.095 0.5   0.235]]\n"
     ]
    }
   ],
   "source": [
    "table6_file = ('data/Table6.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table6_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "\n",
    "table6 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table6.append(a[0])\n",
    "    \n",
    "table6 = np.reshape(table6, (np.shape(rawData)[0], -1))\n",
    "table6_clean = table6[1:, 1:]\n",
    "cpd_x4 = table6_clean.astype(np.float)\n",
    "print(cpd_x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.375 0.11  0.105 0.41 ]\n",
      " [0.307 0.182 0.286 0.268]\n",
      " [0.293 0.318 0.381 0.329]\n",
      " [0.04  0.091 0.    0.   ]\n",
      " [0.173 0.227 0.19  0.146]\n",
      " [0.187 0.182 0.143 0.256]\n",
      " [0.173 0.136 0.381 0.146]\n",
      " [0.693 0.682 0.571 0.646]\n",
      " [0.133 0.182 0.048 0.207]]\n"
     ]
    }
   ],
   "source": [
    "table7_file = ('data/Table7.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table7_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "\n",
    "table7 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table7.append(a[0])\n",
    "    \n",
    "table7 = np.reshape(table7, (np.shape(rawData)[0], -1))\n",
    "table7_clean = table7[1:, 1:]\n",
    "cpd_x5 = table7_clean.astype(np.float)\n",
    "cpd_x5[1,3] = 0.268\n",
    "cpd_x5[2,3] = 0.329\n",
    "cpd_x5[3,3] = 0.\n",
    "cpd_x5[4,3] = 0.146\n",
    "cpd_x5[5,3] = 0.256\n",
    "cpd_x5[8,2] = 0.048\n",
    "cpd_x5[5,0] = 0.187\n",
    "print(cpd_x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.015 0.32  0.14  0.315 0.21 ]\n",
      " [1.    0.687 0.714 0.873 0.809]\n",
      " [0.    0.031 0.036 0.    0.   ]\n",
      " [0.    0.094 0.036 0.032 0.048]\n",
      " [0.    0.187 0.214 0.095 0.143]\n",
      " [0.    0.281 0.214 0.317 0.262]\n",
      " [0.333 0.296 0.392 0.317 0.309]\n",
      " [0.    0.    0.    0.079 0.   ]\n",
      " [0.666 0.234 0.142 0.095 0.167]\n",
      " [0.    0.187 0.25  0.19  0.262]\n",
      " [0.    0.218 0.107 0.206 0.143]\n",
      " [1.    0.656 0.714 0.635 0.643]\n",
      " [0.    0.125 0.179 0.159 0.214]\n",
      " [1.    0.625 0.786 0.746 0.738]\n",
      " [0.    0.187 0.107 0.063 0.048]\n",
      " [0.    0.    0.    0.016 0.024]\n",
      " [0.    0.187 0.107 0.175 0.19 ]]\n"
     ]
    }
   ],
   "source": [
    "table8_file = ('data/Table8.csv')\n",
    "rawData = []\n",
    "\n",
    "with open(table8_file, newline='') as data:\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        rawData.append(row)\n",
    "\n",
    "table8 = []\n",
    "for j in range(np.shape(rawData)[0]):\n",
    "    for i in range(len(rawData[0])):\n",
    "        a = rawData[j][i].split('%')\n",
    "        a = [remove_none(v) for v in a]\n",
    "        a = [maybe_float(v) for v in a]\n",
    "        a = [percentage(v) for v in a]\n",
    "        table8.append(a[0])\n",
    "    \n",
    "table8 = np.reshape(table8, (np.shape(rawData)[0], -1))\n",
    "table8_clean = table8[1:, 1:]\n",
    "table8_clean[6,4] = 0.309\n",
    "cpd_x6 = table8_clean.astype(np.float)\n",
    "cpd_x6[3, 1] = 0.094\n",
    "cpd_x6[10, 0] = 0.\n",
    "cpd_x6[11, 0] = 1.\n",
    "cpd_x6[12, 0] = 0.\n",
    "cpd_x6[4, 1] = 0.187\n",
    "cpd_x6[10, 1] = 0.218\n",
    "cpd_x6[11, 1] = 0.656\n",
    "cpd_x6[12, 1] = 0.125\n",
    "cpd_x6[10, 2] = 0.107\n",
    "cpd_x6[11, 2] = 0.714\n",
    "cpd_x6[12, 2] = 0.179\n",
    "cpd_x6[3, 3] = 0.032\n",
    "cpd_x6[4, 3] = 0.095\n",
    "cpd_x6[10, 3] = 0.206\n",
    "cpd_x6[11, 3] = 0.635\n",
    "cpd_x6[12, 3] = 0.159\n",
    "\n",
    "print(cpd_x6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(xy, y, x):\n",
    "    return np.abs(xy*y - x*y)\n",
    "\n",
    "def xy_corr(a, b, c):\n",
    "    data = []\n",
    "    for j in range(np.shape(a)[0]):\n",
    "        #print(j)\n",
    "        for i in range(np.shape(c)[0]):\n",
    "#             print(i)\n",
    "#             print('c[i, j]', c[i, j])\n",
    "#             print('a[j]', a[j])\n",
    "#             print('b[i]', b[i])\n",
    "            corr = correlation(c[i, j], a[j], b[i])\n",
    "            #print(corr)\n",
    "            data.append(corr)\n",
    "    return np.sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78  0.015 0.055 0.15 ]\n",
      "[0.275 0.32  0.025 0.17  0.21 ]\n",
      "[0.18 0.66 0.16]\n",
      "[0.715 0.105 0.01  0.17 ]\n",
      "[0.375 0.11  0.105 0.41 ]\n",
      "[0.015 0.32  0.14  0.315 0.21 ]\n"
     ]
    }
   ],
   "source": [
    "x1 = margProb[0:-1, 0]\n",
    "x2 = margProb[0:, 1]\n",
    "x3 = margProb[0:-2, 2]\n",
    "x4 = margProb[0:-1, 3]\n",
    "x5 = margProb[0:-1, 4]\n",
    "x6 = margProb[0:, 5]\n",
    "\n",
    "x1x2 = cpd_x1[1:6, 0:]\n",
    "x1x4 = cpd_x1[6:10, 0:]\n",
    "x1x6 = cpd_x1[10:, 0:]\n",
    "\n",
    "x2x3 = cpd_x2[1:4, 0:]\n",
    "x2x5 = cpd_x2[4:, 0:]\n",
    "\n",
    "x3x2 = cpd_x3[1:6, 0:]\n",
    "x3x5 = cpd_x3[6:10, 0:]\n",
    "x3x6 = cpd_x3[10:, 0:]\n",
    "\n",
    "x4x1 = cpd_x4[1:5, 0:]\n",
    "x4x2 = cpd_x4[5:10, 0:]\n",
    "x4x6 = cpd_x4[10:, 0:]\n",
    "\n",
    "x5x2 = cpd_x5[1:6, 0:]\n",
    "x5x3 = cpd_x5[6:, 0:]\n",
    "\n",
    "x6x1 = cpd_x6[1:5, 0:]\n",
    "x6x2 = cpd_x6[5:10, 0:]\n",
    "x6x3 = cpd_x6[10:13, 0:]\n",
    "x6x4 = cpd_x6[13:, 0:]\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print(x4)\n",
    "print(x5)\n",
    "print(x6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x1x2 / x1x4 / x1x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1x2\n",
    "x1x2_corr = xy_corr(x1, x2, x1x2)\n",
    "corr.append(['x1x2', x1x2_corr])\n",
    "\n",
    "#x1x4\n",
    "x1x4_corr = xy_corr(x1, x4, x1x4)\n",
    "corr.append(['x1x4', x1x4_corr])\n",
    "\n",
    "#x1x6\n",
    "x1x6_corr = xy_corr(x1, x6, x1x6)\n",
    "corr.append(['x1x6', x1x6_corr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x2x3 / x2x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2x3\n",
    "x2x3_corr = xy_corr(x2, x3, x2x3)\n",
    "corr.append(['x2x3', x2x3_corr])\n",
    "\n",
    "# x2x5\n",
    "x2x5_corr = xy_corr(x2, x5, x2x5)\n",
    "corr.append(['x2x5', x2x5_corr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x3x2 / x3x5 / x3x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x3x2\n",
    "x3x2_corr = xy_corr(x3, x2, x3x2)\n",
    "corr.append(['x3x2', x3x2_corr])\n",
    "\n",
    "# x3x5\n",
    "x3x5_corr = xy_corr(x3, x5, x3x5)\n",
    "corr.append(['x3x5', x3x5_corr])\n",
    "\n",
    "# x3x6\n",
    "x3x6_corr = xy_corr(x3, x6, x3x6)\n",
    "corr.append(['x3x6', x3x6_corr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x4x1 / x4x2 / x4x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4x1\n",
    "x4x1_corr = xy_corr(x4, x1, x4x1)\n",
    "corr.append(['x4x1', x4x1_corr])\n",
    "\n",
    "# x4x2\n",
    "x4x2_corr = xy_corr(x4, x2, x4x2)\n",
    "corr.append(['x4x2', x4x2_corr])\n",
    "\n",
    "# x4x6\n",
    "x4x6_corr = xy_corr(x4, x6, x4x6)\n",
    "corr.append(['x4x6', x4x6_corr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x5x2 / x5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x5x2\n",
    "x5x2_corr = xy_corr(x5, x2, x5x2)\n",
    "corr.append(['x5x2', x5x2_corr])\n",
    "\n",
    "# x5x3\n",
    "x5x3_corr = xy_corr(x5, x3, x5x3)\n",
    "corr.append(['x5x3', x5x3_corr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x6x1 / x6x2/ x6x3 / x6x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x6x1\n",
    "x6x1_corr = xy_corr(x6, x1, x6x1)\n",
    "corr.append(['x6x1', x6x1_corr])\n",
    "\n",
    "# x6x2\n",
    "x6x2_corr = xy_corr(x6, x2, x6x2)\n",
    "corr.append(['x6x2', x6x2_corr])\n",
    "\n",
    "# x6x3\n",
    "x6x3_corr = xy_corr(x6, x3, x6x3)\n",
    "corr.append(['x6x3', x6x3_corr])\n",
    "\n",
    "# x6x4\n",
    "x6x4_corr = xy_corr(x6, x4, x6x4)\n",
    "corr.append(['x6x4', x6x4_corr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x1x2', 0.15977], ['x1x4', 0.11943000000000005], ['x1x6', 0.16015500000000005], ['x2x3', 0.21852500000000002], ['x2x5', 0.12926000000000004], ['x3x2', 0.21875800000000006], ['x3x5', 0.11551999999999997], ['x3x6', 0.11324000000000001], ['x4x1', 0.11957000000000005], ['x4x2', 0.11569999999999997], ['x4x6', 0.14347000000000001], ['x5x2', 0.12939], ['x5x3', 0.11596500000000005], ['x6x1', 0.16036999999999996], ['x6x2', 0.17531500000000003], ['x6x3', 0.09433999999999998], ['x6x4', 0.14307000000000003]]\n"
     ]
    }
   ],
   "source": [
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['x1x2', '0.15977']],\n",
       "\n",
       "       [['x1x6', '0.16015500000000005']],\n",
       "\n",
       "       [['x2x3', '0.21852500000000002']],\n",
       "\n",
       "       [['x2x5', '0.12926000000000004']],\n",
       "\n",
       "       [['x3x2', '0.21875800000000006']],\n",
       "\n",
       "       [['x4x6', '0.14347000000000001']],\n",
       "\n",
       "       [['x5x2', '0.12939']],\n",
       "\n",
       "       [['x6x1', '0.16036999999999996']],\n",
       "\n",
       "       [['x6x2', '0.17531500000000003']],\n",
       "\n",
       "       [['x6x4', '0.14307000000000003']]], dtype='<U19')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def threshold(data, coeff):\n",
    "    index = np.argwhere((data[:, 1].astype(float) >= coeff))\n",
    "    return data[index]\n",
    "\n",
    "threshold(np.array((corr)), 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2x1\n",
    "x1x2_x2 = x1x2 *x1\n",
    "x2x1 = x1x2_x2.T / x2\n",
    "\n",
    "# x2x6\n",
    "x6x2_x6 = x6x2 *x6\n",
    "x2x6 = x6x2_x6.T / x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -2302.334898666883\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x2', 'x3')])\n",
    "\n",
    "cpd_x2 = TabularCPD('x2', np.shape(x2)[0], [x2])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x2,cpd_x2x3)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "estimator = BayesianEstimator(model, sample)\n",
    "\n",
    "estimator.get_parameters()\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -3641.8300251491364\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x6', 'x2'), ('x2', 'x3')])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', np.shape(x6)[0], [x6])\n",
    "cpd_x6x2 = TabularCPD('x2', np.shape(x6x2)[0], x6x2, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x6, cpd_x6x2, cpd_x2x3)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -4399.982028229801\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x6', 'x2'), ('x6', 'x1'), ('x2', 'x3')])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', np.shape(x6)[0], [x6])\n",
    "cpd_x6x1 = TabularCPD('x1', np.shape(x6x1)[0], x6x1, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x6x2 = TabularCPD('x2', np.shape(x6x2)[0], x6x2, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x6, cpd_x6x2, cpd_x6x1, cpd_x2x3)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -4863.090586565958\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x6', 'x2'), ('x2', 'x3'), ('x2', 'x5')])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', np.shape(x6)[0], [x6])\n",
    "cpd_x6x2 = TabularCPD('x2', np.shape(x6x2)[0], x6x2, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x2x5 = TabularCPD('x5', np.shape(x2x5)[0], x2x5, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x6, cpd_x6x2, cpd_x2x5, cpd_x2x3)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -6465.23998164203\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x6', 'x4'), ('x6', 'x1'), ('x1', 'x2'), ('x2', 'x3'), ('x2', 'x5')])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', np.shape(x6)[0], [x6])\n",
    "cpd_x6x4 = TabularCPD('x4', np.shape(x6x4)[0], x6x4, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x6x1 = TabularCPD('x1', np.shape(x6x1)[0], x6x1, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x1x2 = TabularCPD('x2', np.shape(x1x2)[0], x1x2, evidence=['x1'], evidence_card=[np.shape(x1)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x2x5 = TabularCPD('x5', np.shape(x2x5)[0], x2x5, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x6, cpd_x6x4, cpd_x6x1, cpd_x1x2, cpd_x2x3, cpd_x2x5)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -6429.554698850261\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x6', 'x4'), ('x6', 'x2'), ('x2', 'x3'), ('x2', 'x1'), ('x3', 'x5')])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', np.shape(x6)[0], [x6])\n",
    "cpd_x6x4 = TabularCPD('x4', np.shape(x6x4)[0], x6x4, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x6x2 = TabularCPD('x2', np.shape(x6x2)[0], x6x2, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x2x1 = TabularCPD('x1', np.shape(x2x1)[0], x2x1, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x3x5 = TabularCPD('x5', np.shape(x3x5)[0], x3x5, evidence=['x3'], evidence_card=[np.shape(x3)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x6, cpd_x6x4, cpd_x6x2, cpd_x2x3, cpd_x2x1, cpd_x3x5)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -6481.007156260817\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x1', 'x6'), ('x1', 'x2'), ('x6', 'x4'), ('x2', 'x3'), ('x2', 'x5')])\n",
    "\n",
    "cpd_x1 = TabularCPD('x1', np.shape(x1)[0], [x1])\n",
    "cpd_x6x4 = TabularCPD('x4', np.shape(x6x4)[0], x6x4, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x1x6 = TabularCPD('x6', np.shape(x1x6)[0], x1x6, evidence=['x1'], evidence_card=[np.shape(x1)[0]])\n",
    "cpd_x1x2 = TabularCPD('x2', np.shape(x1x2)[0], x1x2, evidence=['x1'], evidence_card=[np.shape(x1)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x2x5 = TabularCPD('x5', np.shape(x2x5)[0], x2x5, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x1, cpd_x6x4, cpd_x1x6, cpd_x1x2, cpd_x2x3, cpd_x2x5)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2Score:  -6461.5366229964675\n"
     ]
    }
   ],
   "source": [
    "model = BayesianModel([('x4', 'x6'), ('x6', 'x1'), ('x1', 'x2'), ('x2', 'x3'), ('x2', 'x5')])\n",
    "\n",
    "cpd_x4 = TabularCPD('x4', np.shape(x4)[0], [x4])\n",
    "cpd_x4x6 = TabularCPD('x6', np.shape(x4x6)[0], x4x6, evidence=['x4'], evidence_card=[np.shape(x4)[0]])\n",
    "cpd_x6x1 = TabularCPD('x1', np.shape(x6x1)[0], x6x1, evidence=['x6'], evidence_card=[np.shape(x6)[0]])\n",
    "cpd_x1x2 = TabularCPD('x2', np.shape(x1x2)[0], x1x2, evidence=['x1'], evidence_card=[np.shape(x1)[0]])\n",
    "cpd_x2x3 = TabularCPD('x3', np.shape(x2x3)[0], x2x3, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "cpd_x2x5 = TabularCPD('x5', np.shape(x2x5)[0], x2x5, evidence=['x2'], evidence_card=[np.shape(x2)[0]])\n",
    "\n",
    "model.add_cpds(cpd_x4, cpd_x4x6, cpd_x6x1, cpd_x1x2, cpd_x2x3, cpd_x2x5)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "sample = inference.forward_sample(size=1000)\n",
    "\n",
    "print('K2Score: ', K2Score(sample).score(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting BN5 to Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x6', 'x2', 'x4', 'x3', 'x5']\n",
      "[('x1', 'x6'), ('x1', 'x2'), ('x6', 'x4'), ('x2', 'x3'), ('x2', 'x5')]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "G = BayesianModel([('x1', 'x6'), ('x1', 'x2'), ('x6', 'x4'), ('x2', 'x3'), ('x2', 'x5')])\n",
    "mm = G.to_markov_model()\n",
    "print(mm.nodes())\n",
    "print(mm.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
